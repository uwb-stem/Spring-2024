

{
    "csse": [
      
        {
           "time": "2:00-2:15",
           "projectId": "csse-1-200",
           "title": "Impact of Data Augmentation on Machine Learning Performance",
           "studentName": "Jaylon Nelson-Sellers",
           "studentMajor": "CSSE",
           "projectType": "Faculty Research",
           "facultyAdvisor": "Dr. Wooyoung Kim",
           "posterLink": "./posters/csse/Nelson-Sellers_497_Poster.jpg",
           "abstract": "This study investigates the effect of dataset dimensionality on the performance of machine learning (ML) and deep learning (DL) models, specifically when complex DL approaches outperform classic ML models such as Random Forests. It answers three questions: (1) when to employ DL instead of ML models, (2) the advantages of augmenting tabular data for DL, and (3) performance comparisons to determine the best generalist model.\n\n Scalable Artificial Neural Networks (ANNs) were built and tested using a variety of datasets for classification and regression, including tabular, picture, and sequential data. ML models, including Decision Trees, Random Forests, K-nearest neighbors, ANNs, CNNs, LSTMs, and Transformers, were tested on eight datasets. Performance was assessed using mean square error, accuracy, and F1 score. The results demonstrated that DL models favor naturally augmentable datasets in two dimensions (for example, photos or sequential data). For tabular data, augmenting to two dimensions and training using CNNs provided minimal advantage. Contrary to expectations, CNNs outperformed other models, whereas Transformers underperformed. Key findings: (1) DL models excel at image classification and sequential data forecasting; (2) Random Forests outperform DL models for most tabular data with less complexity; and (3) CNNs are best for image tasks, while Recurrent Networks are best for sequential data, though CNNs also perform well.\n\n The study recommends ML and DL models based on dataset features, determining when DL models are useful and when regular ML models are sufficient."
       },
       {
        "time": "2:15-2:30",
        "projectId": "csse-1-215",
        "title": "Predicting Electrostatic Discharge Protection",
        "studentName": "Joshua Feng",
        "studentMajor": "CSSE",
        "projectType": "Internship or Job opportunity",
        "facultyAdvisor": "Dr. Yang Peng",
        "posterLink": "./posters/csse/fengjoshua_4019011_121234879_CSS 497 Poster - Joshua Feng.jpg",
        "abstract": "Electrostatic discharge (ESD) is the release of static electricity when objects come into contact. This phenomenon often occurs around our living environment, with examples including walking across a carpeted floor and getting shocked after touching a metal doorknob, or when lightning strikes a house, which is the most extreme form. ESD won’t physically harm a person but can cause damage when transferred onto electronics. ESD is a big concern when designing electronic systems because IC chips are intricate, and even one failed transistor will cause system malfunctions. ESD protection design inside IC chips is critical to prevent ESD from damaging the circuit in manufacturing or use.ESD protection devices are designed for this purpose and are sophisticated. AIP Technology Corporation uses different tools and methods to predict ESD device capabilities for IC design companies. ESD devices are tested following the Transmission Line Pulse (TLP) to characterize their capabilities through three main metrics, Vt (trigger voltage), Vh (holding voltage), and It2 (secondary breakdown current). These metrics are hard to predict due to ESD devices behaving variably, requiring manual verification which is costly and sometimes inaccurate. To automate this process and more accurately calculate these metrics, my project uses machine learning to train from the ESD device data to predict these voltage values.During my internship, I parsed and sorted through thousands of ESD protection device data files, creating an algorithm that calculates the ESD metrics. Accomplishing this required an understanding of the correlations between voltages, currents, leakage, and other information that create an IV curve for each device. Then, I disregarded noise (bad data) from being used and prepared the data for machine learning by grouping them based on their behavior patterns. I utilized deep-learning (Convolutional Neural Networks) using TensorFlow to train and predict from the ESD data. Finally, I cross-verified the machine-learning predictions with verified ESD values for each data file and plotted predicted and expected values on a graph to visualize. As a result of the project, I achieved around a 90% accuracy rate when predicting Vt (trigger voltage), Vh (holding voltage), and It2 (secondary breakdown current). This project improves the time-cost efficiency of the process of manually verifying ESD protection devices and creates a foundation that improves ESD device design."
    },
    {
        "time": "2:30-2:45",
        "projectId": "csse-1-230",
        "title": "Instrument In The Middle; Standard Commands for Programmable Instruments (SCPI) Translator",
        "studentName": "Jeremy Edwards",
        "studentMajor": "CSSE",
        "projectType": "Internship or Job opportunity",
        "facultyAdvisor": "Dr. Afra Mashhadi",
        "posterLink": "./posters/csse/edwardsjeremye_4029004_121256892_InstrumentIntheMiddlePoster_SM.png",
        "abstract": "At Crane Aerospace & Electronics, we prioritize collaboration and working closely with our customers to develop mission-critical products that drive their businesses forward. Our products are designed for long service lives, so our test equipment needs to remain in service for extended periods as well. Due to test software developed over a decade ago, we face challenges with replacing damaged or outdated test equipment due to the lack of software abstraction layers at that time. This led to the need for the \"Instrument In the Middle\" concept, which aims to ensure uptime temporarily while the test software is being rewritten with our current abstraction layer architecture supporting driver development following IVI foundation standards.\n\n Using Python, Linux GPIB, and pyVISA on a Raspberry Pi 3B+ with Raspberry Pi OS 64-bit Bookworm (March 15, 2024), along with Prologix's GPIB-USB Controller 6.0 and National Instruments GPIB-USB-HS+, I have successfully created a Python project controlled by two simple *.csv files to translate the functions from Automated Test Equipment (ATE) test software with hard-coded AC source functions from a California Instruments 3000Ls at an approximate cost of $25k to a California Instruments CSW5550 at an approximate cost of $38k. The *.csv simplification allows ease of deployment on other legacy GPIB instrument projects in the future. \n\n The California Instruments Ls was missing a phase, and its repair was not feasible because the test software required its presence during initiation. However, with additional instructions and the California Instruments CSW connected using vendor software the minimum functions could be performed. The \"Instrument In the Middle\" now allows the California Instruments Ls to be sent out for repair while enabling the use of the California Instruments CSW for all the AC source functions in the ATE test software making its use transparent to the operator. Once tool verification and release are completed this tool can be used within the production environment after customer notification. This entire process can be achieved at a hardware cost of approximately $0.4k to $1.4k for the \"Instrument In the Middle\" plus the replacement device while the test software is being rewritten.\n\n "
    },
    {
        "time": "2:45-3:00",
        "projectId": "csse-1-245",
        "title": "Emotion Classification using EGG - A Privacy Risk",
        "studentName": "Chris Dimiputra",
        "studentMajor": "CSSE",
        "projectType": "Faculty Research",
        "facultyAdvisor": "Dr. Geetha Thamilarasu",
        "posterLink": "./posters/csse/dimiputrachrishansel_4262369_121283584_Capstone Poster 48x36 (2MB).png",
        "abstract": "Understanding human emotions is a complex and nuanced process, traditionally requiring significant time and personal interaction. The advent of machine learning offers the potential to classify and profile emotions efficiently, promising revolutionary advancements across various fields. These advancements include enhancing user experiences, providing an additional layer of authentication, improving mental health therapy, and facilitating better communication. However, the deployment of emotion-detecting technologies also brings substantial privacy concerns. These concerns encompass the potential for creating highly personalized phishing attacks, enabling sophisticated social engineering schemes, and facilitating manipulation and exploitation. \n\n This research aims to demonstrate how a malicious attacker could utilize machine learning to create an emotional profile from EEG data. By showcasing this potential misuse, we seek to raise awareness about the vulnerability of EEG data to manipulation and highlight the importance of safeguarding such data. \n\n In this study, data was collected from a single individual who viewed images and listened to different music genres to evoke various emotions. The EEG data was captured and preprocessed to remove noise from the signal. Features were then extracted from the data and fed into several machine learning models. These models were trained and fine-tuned to achieve the best classification accuracy. The experimental results showed classification accuracies of 80%, 79%, 68%, and 77% for pop, rap, classical, and EDM music genres, respectively. \n\n The significance of this study lies in its demonstration of the ease with which machine learning can be used to exploit EEG data, highlighting the urgent need for robust data protection measures. This research underscores the dual-use nature of emotion-detecting technologies and calls for a balanced approach that maximizes benefits while mitigating risks. By bringing attention to these issues, we aim to foster the development of ethical standards and safeguards to protect individuals from potential abuses of their emotional data. "
    },
    {
        "time": "3:00-3:15",
        "projectId": "csse-1-300",
        "title": "Test-Driven Development: Potential As A Magic Bullet for UW CSS",
        "studentName": "Kira Dzius",
        "studentMajor": "CSSE",
        "projectType": "Faculty Research",
        "facultyAdvisor": "Dr. David Socha",
        "posterLink": "./posters/csse/KiraDzius.png",
        "abstract": "Problem Overview\n Modern computer science education faces a significant challenge: students often lack a genuine understanding of coding assignments, a problem compounded by the rise of AI technologies and widespread plagiarism. Many resort to copying solutions from online sources or using AI tools, resulting in submissions that sometimes contain default comments or other indicators of a lack of engagement. This highlights a critical educational flaw—the failure to engage students deeply with materials designed to develop their coding skills—underscoring the need for innovative educational strategies that promote meaningful interaction with and comprehension of coding processes.\n\n Purpose and Methodology\n This project introduced a novel framework using Test-Driven Development (TDD) and the Red-Green-Refactor Cycle (RGR), inspired by its successful use in the Software-Engineering-Studio class. Unlike the unstructured coding assignments typical in other classes, this structured, iterative framework starts with test creation (Red), followed by coding to pass the tests (Green), and code refinement (Refactor). This method fosters a deep, lasting mastery of coding skills.\n\n Implementation and Results\n The project's practical application involved creating several key resources:\n - Home-of-TDD: A detailed guide on TDD, offering abundant resources, detailed code examples, and in-depth analyses of TDD principles and methodologies.\n - Sample-TDD: An introductory, self-assessable assignment on TDD and RGR available in six languages, serving as a primary resource for understanding TDD and RGR.\n - walkthru: A detailed walkthrough providing extensive commentary and thought processes on completing assignments using TDD, equivalence partitioning, and the RGR method.\n - level1: A team-based project that extends the principles learned in Sample-TDD to a larger scale, focusing on cross-team integration and multi-file development, using TDD and RGR.\n The overall effort included interviewing 15 students across introductory and advanced CSS courses, conducting a focus group with 12 students, and analyzing surveys from 12 participants engaging deeply with the TDD resources.\n\n These activities revealed stronger engagement and satisfaction with the TDD-RGR framework compared to conventional methods. Students reported a preference for the structured, calm learning environment provided by TDD, expressing a high intention to continue employing this methodology.\n\n Significance and Conclusion\n The capstone project substantiates Test-Driven Development as a transformative educational tool capable of significantly enhancing coding skills among computer science students. The method's clarity and structured approach reduce the entry barrier to complex coding concepts, making it a scalable and effective educational strategy. These findings advocate for the integration of TDD into future curricula, potentially on a global scale."
    },
    {
        "time": "3:15-3:30",
        "projectId": "csse-1-315",
        "title": "Creating a catagory game for the Luna mHealth mobile app",
        "studentName": "Mykyta Skiba",
        "studentMajor": "CSSE",
        "projectType": "Faculty Research",
        "facultyAdvisor": "Dr. David Socha",
        "posterLink": "./posters/csse/MykytaSkibaPosterFinal.png",
        "abstract": "During my capstone, I worked on the Luna mHealth app. It is a mobile app, which makes it easy for domain experts to provide educational resources in various topics to communities that live in areas with bad internet connectivity or other technological factors that prohibit them from accessing other online resources. The app is able to parse PowerPoint files into a JSON file that follows Luna's declarative language. Then using Luna’s language the app is able to display it with additional interactive features that are not available in PowerPoint.\n\n Our team consisted of 10 developers, most of which were master’s students. Each of us had an area of the app that we were primarily developing. My area was working on educational game experiences. The inclusion of learning games in the app's design is to help reinforce learning by the users of the app and to empower the content module creators to be able to create their own learning experiences. \n\n The product I have created is a simple tile matching game that works similarly to CAPTCHAs or the NYT Connections. The game is integrated into the rest of the Luna code base. Whenever a game needs to be displayed, it retrieves all of its data entirely from Luna's declarative language file and builds itself based on that data. \n\n During this project I gained experience in a startup-like environment. The next steps in the project were not obvious most of the time. Unlike most assignments that I had in my coursework, I had to learn how to keep making progress, despite a lack of direction and when to ask for help. Thankfully there was a team of masters students to help me make progress."
    },
    {
        "time": "3:30-3:45",
        "projectId": "csse-1-330",
        "title": "A Day in the Life of a Business Intelligence Analyst",
        "studentName": "Blaine Wenzel",
        "studentMajor": "CSSE",
        "projectType": "Internship or Job opportunity",
        "facultyAdvisor": "Mr. Mark Kochanski",
        "posterLink": "./posters/csse/BlaineWenzel.jpg",
        "abstract": "What is life like in an experienced technical role? What will be expected of me? What will be my responsibilities? How do I communicate with other non-technical people about technical things? These questions are not answered in traditional schooling environments or internships, but are often essential to know to create realistic expectations and obtainable goals for the future of graduating technical students.\n\n I have been lucky enough to have worked at Boeing as a Business Intelligence analyst for over 7 years in their Commercial Airplanes organization in both Everett and Renton, obtaining that level of “experienced” in this role. As a Business Intelligence analyst, I have chosen to create 5 dashboards and use the events that occurred during that time to portray what it can be like to be in an experienced technical role.\n\n What I have found is that while you do have an elevated level of responsibility, expectations, and communication, you also have an elevated level of influence, authority, and freedom. You will likely have larger and more important projects, but also have the ability to change course with your input/opinions or push back on deadlines. Communicating with non-technical stakeholders about issues or ideas by translating technical to business terminology and back again will be imperative, but comes easier the more experience you have and the more you know the stakeholders.\n\n While my personal findings/experience won’t apply to everyone, it can at least paint a picture as to what technical job roles will generally evolve into. In sharing this knowledge, I hope that I can instill a bit of confidence and knowledge into students that are getting ready to tackle the large, daunting world ahead of them. "
    },
    {
        "time": "3:45-4:00",
        "projectId": "csse-1-345",
        "title": "Project M | A 2D Multiplayer Party Game",
        "studentName": "Anthony Hu",
        "studentMajor": "CSSE",
        "projectType": "Individual Project - Student Defined",
        "facultyAdvisor": "Mr. Mark Kochanski",
        "posterLink": "./posters/csse/Anthony_Hu_Capstone_Poster (1).png",
        "abstract": "Project M is a 2D multiplayer party game where players compete against each other as mouse cursors and play a series of minigames. The purpose of Project M was to learn the technical competencies associated with making a multiplayer game and validate a potential game idea for future development.\n\n Going into Project M, I had little experience with creating games. My partner and I had some prior experience with Unity. We decided to work with Unity as our game engine, C# as our scripting language (supported natively), and Unity Version Control as our version control system (easier to handle conflicts).\n\n Development of Project M faced and will continue to face two major obstacles that will determine its success.\n\n The first obstacle was imitating a mouse cursor and creating a fun movement system. Playtesting the first prototype, we realized that directly mimicking mouse movement creates an awkward and unplayable movement system. Linearly moving a virtual mouse based on a physical mouse, has a major limitation when virtually moving longer distances. The player has to constantly pick up and readjust their physical mouse. Instead, we chose to have the physical mouse act as a joystick. There are still various gameplay issues to resolve, but this is much more convenient and smooth, and there are various systems we can supplement it with. Though it is not intuitive in that it does not mimic standard mouse movement, a fun movement system takes precedence over realism or expectation.\n\n The second obstacle is developing a strong server authoritative solution with client prediction. Project M aims to be a published game in the future with matchmaking. Cheating is a major issue and we chose to develop a server authoritative solution to help prevent this. Implementing multiplayer, we stayed in the Unity ecosystem and used Netcode for GameObjects (NGO), Lobby, and Relay. Developing a simple multiplayer solution with NGO is not difficult, but a server authoritative client prediction solution is not supported and is much more complex. This is where most of my time was spent.\n\n After two quarters of work, Project M has a viable base player design, relatively scalable game architecture, playtesting environment, basic multiplayer connection flow and loop, and a simple server authoritative solution with client prediction. The work accomplished and knowledge obtained from Project M will serve as a baseline for future development. "
    },
    {
        "time": "4:00-4:15",
        "projectId": "csse-1-400",
        "title": "Platform Engineer Internship @ Carrix",
        "studentName": "Nathan Balzotti",
        "studentMajor": "CSSE",
        "projectType": "Internship or Job opportunity",
        "facultyAdvisor": "Mr. Mark Kochanski",
        "posterLink": "./posters/csse/balzottinathanlawrence_4000308_121300743_Capstone Poster-6.png",
        "abstract": "Within the Winter and Spring Quarters, I took on an internship at Carrix, a global network and logistics company. \n\n At Carrix, I undertook the role of an interim platform engineer within the Enterprise Applications department. My primary focus was on integrations with their child software company, Tideworks. One of my key projects involved addressing communication issues between two critical ticketing platforms, ServiceNow and Zendesk. Utilizing the Boomi Atomsphere integration platform, I designed and implemented a custom REST API that facilitated seamless data translation between these systems, as well as a front end that utilized it within each ticketing platform. This integration not only enhanced the efficiency of ticket management but also replaced a costly pre-built solution, resulting in significant cost savings for the company. \n\n Another project I spearheaded was the development of a dynamic dashboard for Oracle Database queries. The existing systems in IT lacked an intuitive method for users to execute queries without the ability to write an SQL script. To address this, I created user-friendly custom visuals in Power BI, enabling custom query formation and enhancing data accessibility. \n\n Both projects, especially the ticket integration, required me to navigate a large array of enterprise platforms, as well as multiple different organizations with varying requirements. Through these projects, I gained invaluable hands-on industry experience, honed my development skills, and contributed meaningfully to Carrix's enterprise technology. "
    },
    {
        "time": "4:15-4:30",
        "projectId": "csse-1-415",
        "title": "Why Names Matter: Impact of Test-Driver Design on Students",
        "studentName": "Oliver Schwab",
        "studentMajor": "CSSE",
        "projectType": "Faculty Research",
        "facultyAdvisor": "Mr. Mark Kochanski",
        "posterLink": "./posters/csse/schwaboliver_4261400_121298789_ColloquiumPoster_OliverSchwab_CSS497_Spring2024-1.png",
        "abstract": "Research & Purpose\n The purpose of this capstone project was to identify potential trends in the attitudes students have towards Test-Driven Development (TDD). Using CSS 390: Software Engineering Studio and CSS 508: Software Testing and Quality students as research participants, both quantitative and qualitative data was analyzed to assess whether there is merit to the idea of TDD having positive impacts on student demeanor while they program, such as increased confidence and reduced stress. Alongside this research, impacts on the way students feel about their design approach while practicing TDD, and student satisfaction with the TDD tutorial ‘sample-TDD’ (part of Kira Dzius’s capstone project) was also analyzed. \n\nResults\n Multiple trends were identified through qualitative thematic analysis, though the results of this research are limited in terms of credibility due to low sample size and understanding of TDD as a design method. Analysis shows that students potentially feel a greater sense of confidence and less stress with using TDD, with some emphasizing this effect comes from unit test coverage, and some claiming it stems from the granularity and iterative nature of the method. Students also reported that their work was higher quality when using TDD, and that they had a greater consideration of edge cases when testing their code. As for the reception of sample-tdd, students overwhelmingly reported that they enjoyed the content, found the tutorial was easy to get started with, and felt supporting materials bolstered the experience with additional learnings. Lastly, students overall seemed to report more about the results of their experience with unit testing, rather than TDD’s Red-Green-Refactor pattern, which suggests students may not truly understand the nature of the method as a form of design rather than testing.\n\n Academic Merit\n Using this data, sample-tdd has proven to be effective and will likely be used in the future for CSS 390 and CSS 508 as course material. Data on the impact of TDD for students is also important for the future of teaching the methodology at University of Washington Bothell, as it suggests that TDD can teach application of design principles. Also, the possibility that students do not understand the theory behind TDD suggests that it needs to be taught more effectively moving forward. For future research on this topic, this capstone can serve as a basis for observing students interacting with TDD using a greater sample size and clearer definitions of the method."
    },
    {
        "time": "4:30-4:45",
        "projectId": "csse-1-430",
        "title": "Teaching Tools Scheduler: Work with Canvas Scheduler",
        "studentName": "Mussie Gera",
        "studentMajor": "CSSE",
        "projectType": "Faculty Research",
        "facultyAdvisor": "Mr. Mark Kochanski",
        "posterLink": "./posters/csse/geramussie_4199844_121300838_Teaching_Tools_Poster.jpeg",
        "abstract": "Over the capstone project, I focused on creating a Canvas Calendar Scheduler designed to optimize appointment scheduling between instructors and students. This tool integrates the Canvas API and Google services into a full-stack web application, utilizing a Python Flask backend and a React JavaScript frontend.\n\n I developed the calendar scheduler to handle CRUD operations for scheduling information using Canvas Learning Management System (LMS) REST APIs. This involved creating, reading, updating, and deleting appointment slots and availability, streamlining the process, and ensuring efficiency. The tool displays all course appointments, office hours, and events in one centralized location, making it easier for both instructors and students to manage their schedules.\n\n The primary aim was to facilitate better interactions between instructors and students, improving the management of appointments, office hours, and academic support. By centralizing scheduling tasks, the tool reduces reliance on multiple platforms and enhances the user experience. The project also provides a valuable learning experience in virtual collaboration and project management using Azure DevOps.\n\n The project resulted in a functional scheduler that significantly improved the scheduling process for both instructors and students. By integrating the Canvas API, I ensured that the tool could seamlessly access and manage relevant data. The scheduler provides a user-friendly interface that allows students to reserve slots that fit their schedules and enables instructors to efficiently manage their time.\n\n This project is significant because it streamlines academic scheduling, fosters effective communication, and provides a centralized platform for managing academic activities. The project built upon previous work by incorporating lessons learned from past students' codebases. \n\n In conclusion, the Canvas Calendar Scheduler Project provided a comprehensive solution to academic scheduling challenges, leveraging development techniques to enhance efficiency and user experience in an educational environment. This tool not only simplifies the scheduling process but also supports effective communication between instructors and students, ultimately contributing to a more organized and accessible academic environment. "
    }  
    ]
}


